{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>babbage_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[-0.006444347091019154, 0.013177386485040188, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[-0.006633083801716566, 0.01087373960763216, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[-0.005033580120652914, 0.01030619814991951, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[-0.01348057109862566, 0.019621720537543297, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>[-0.026726385578513145, 0.0207790806889534, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet           Sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                  babbage_similarity  \n",
       "0  [-0.006444347091019154, 0.013177386485040188, ...  \n",
       "1  [-0.006633083801716566, 0.01087373960763216, -...  \n",
       "2  [-0.005033580120652914, 0.01030619814991951, -...  \n",
       "3  [-0.01348057109862566, 0.019621720537543297, 0...  \n",
       "4  [-0.026726385578513145, 0.0207790806889534, 0....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('embedded_30_tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['babbage_similarity'] = df.babbage_similarity.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['babbage_similarity'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              10\n",
       "Neutral                6\n",
       "Extremely Positive     6\n",
       "Extremely Negative     4\n",
       "Negative               4\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "sentiment_column = df[[\"Sentiment\"]]\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "df['sentiment_encoded'] = encoder.fit_transform(sentiment_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral',\n",
       "        'Positive'], dtype=object)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.babbage_similarity.values,\n",
    "    df.sentiment_encoded.values,\n",
    "    test_size = 0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 0.0027842 ,  0.01915837,  0.01003171, ..., -0.01389959,\n",
       "              -0.01993004, -0.02673217])                              ,\n",
       "       array([-0.01107579,  0.01640144, -0.00014396, ...,  0.00975886,\n",
       "               0.00374097, -0.01413418])                              ,\n",
       "       array([-0.01232978,  0.01202253,  0.00701727, ...,  0.01036732,\n",
       "              -0.04452201, -0.00075574])                              ,\n",
       "       array([-0.00644435,  0.01317739, -0.01283282, ..., -0.00715676,\n",
       "              -0.02316985, -0.01435078])                              ,\n",
       "       array([-0.02672639,  0.02077908,  0.00284367, ..., -0.0013158 ,\n",
       "              -0.00661774, -0.00029275])                              ,\n",
       "       array([-0.00212527,  0.0302756 ,  0.01443285, ..., -0.01366298,\n",
       "              -0.02641694, -0.0105742 ])                              ,\n",
       "       array([-0.03036317,  0.00143428,  0.00986999, ...,  0.0138219 ,\n",
       "              -0.00641696, -0.00299817])                              ,\n",
       "       array([-0.0019754 ,  0.02380968, -0.02655475, ...,  0.00797786,\n",
       "              -0.01868173,  0.00893101])                              ,\n",
       "       array([-0.01286806,  0.00225845, -0.01864852, ...,  0.03352086,\n",
       "               0.00677292, -0.02565865])                              ,\n",
       "       array([ 0.00950403,  0.00174806, -0.00678859, ..., -0.00327307,\n",
       "              -0.02024941, -0.02445833])                              ,\n",
       "       array([-0.00663308,  0.01087374, -0.01619253, ...,  0.03080379,\n",
       "              -0.0017879 ,  0.00177379])                              ,\n",
       "       array([-0.00503358,  0.0103062 , -0.0015503 , ...,  0.01938043,\n",
       "              -0.01064637, -0.00554383])                              ,\n",
       "       array([-0.0023746 , -0.0094158 , -0.00695253, ..., -0.01274874,\n",
       "              -0.00691852, -0.01382733])                              ,\n",
       "       array([-0.01348057,  0.01962172,  0.00049645, ..., -0.00032531,\n",
       "               0.01231038, -0.01046617])                              ,\n",
       "       array([-0.0067606 ,  0.00676982, -0.01950298, ...,  0.00636428,\n",
       "               0.0021798 , -0.00333652])                              ,\n",
       "       array([-0.01645366,  0.00538605, -0.00102597, ..., -0.00332219,\n",
       "              -0.00160509, -0.01773106])                              ,\n",
       "       array([ 0.00209155,  0.0267292 , -0.01776785, ..., -0.00764037,\n",
       "               0.00196937, -0.01817431])                              ,\n",
       "       array([-0.02158849,  0.01273405,  0.00676613, ..., -0.0012205 ,\n",
       "              -0.00552242,  0.00389354])                              ,\n",
       "       array([-0.0045678 ,  0.00612332,  0.00396781, ..., -0.00451595,\n",
       "               0.00502952, -0.00598011])                              ,\n",
       "       array([ 0.00312659,  0.01321545, -0.01187706, ...,  0.00098662,\n",
       "               0.00834053,  0.00311773])                              ,\n",
       "       array([-0.0213134 ,  0.0097663 , -0.01287802, ...,  0.01964507,\n",
       "              -0.00755904, -0.01678641])                              ,\n",
       "       array([ 6.66830223e-03, -3.29576069e-05, -2.43519037e-03, ...,\n",
       "              -1.08650681e-02, -1.50909107e-02,  2.59511336e-03])    ,\n",
       "       array([-0.02254736, -0.00929979, -0.00516211, ...,  0.01705044,\n",
       "               0.01365235, -0.00498471])                              ,\n",
       "       array([ 0.00220057,  0.01720337, -0.02143496, ...,  0.00224594,\n",
       "              -0.00486919, -0.001477  ])                              ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hid1 = torch.nn.Linear(2048, 10)  # 2048-(10-10)-5\n",
    "        self.hid2 = torch.nn.Linear(10, 10)\n",
    "        self.oupt = torch.nn.Linear(10, 5)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "        torch.nn.init.zeros_(self.hid1.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "        torch.nn.init.zeros_(self.hid2.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "        torch.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        z = torch.tanh(self.hid1(input))\n",
    "        z = torch.tanh(self.hid2(z))\n",
    "        z = self.oupt(z)  # no softmax: CrossEntropyLoss() \n",
    "        return z\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model2 = BasicNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.001, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 1.605\n",
      "[1,    20] loss: 1.611\n",
      "[2,    10] loss: 1.604\n",
      "[2,    20] loss: 1.610\n",
      "[3,    10] loss: 1.604\n",
      "[3,    20] loss: 1.609\n",
      "[4,    10] loss: 1.603\n",
      "[4,    20] loss: 1.608\n",
      "[5,    10] loss: 1.603\n",
      "[5,    20] loss: 1.607\n",
      "[6,    10] loss: 1.603\n",
      "[6,    20] loss: 1.606\n",
      "[7,    10] loss: 1.602\n",
      "[7,    20] loss: 1.605\n",
      "[8,    10] loss: 1.602\n",
      "[8,    20] loss: 1.604\n",
      "[9,    10] loss: 1.601\n",
      "[9,    20] loss: 1.603\n",
      "[10,    10] loss: 1.601\n",
      "[10,    20] loss: 1.602\n",
      "[11,    10] loss: 1.601\n",
      "[11,    20] loss: 1.601\n",
      "[12,    10] loss: 1.600\n",
      "[12,    20] loss: 1.601\n",
      "[13,    10] loss: 1.600\n",
      "[13,    20] loss: 1.600\n",
      "[14,    10] loss: 1.600\n",
      "[14,    20] loss: 1.599\n",
      "[15,    10] loss: 1.599\n",
      "[15,    20] loss: 1.598\n",
      "[16,    10] loss: 1.599\n",
      "[16,    20] loss: 1.597\n",
      "[17,    10] loss: 1.599\n",
      "[17,    20] loss: 1.596\n",
      "[18,    10] loss: 1.599\n",
      "[18,    20] loss: 1.596\n",
      "[19,    10] loss: 1.598\n",
      "[19,    20] loss: 1.595\n",
      "[20,    10] loss: 1.598\n",
      "[20,    20] loss: 1.594\n",
      "[21,    10] loss: 1.598\n",
      "[21,    20] loss: 1.593\n",
      "[22,    10] loss: 1.598\n",
      "[22,    20] loss: 1.593\n",
      "[23,    10] loss: 1.598\n",
      "[23,    20] loss: 1.592\n",
      "[24,    10] loss: 1.597\n",
      "[24,    20] loss: 1.591\n",
      "[25,    10] loss: 1.597\n",
      "[25,    20] loss: 1.591\n",
      "[26,    10] loss: 1.597\n",
      "[26,    20] loss: 1.590\n",
      "[27,    10] loss: 1.597\n",
      "[27,    20] loss: 1.589\n",
      "[28,    10] loss: 1.597\n",
      "[28,    20] loss: 1.589\n",
      "[29,    10] loss: 1.597\n",
      "[29,    20] loss: 1.588\n",
      "[30,    10] loss: 1.596\n",
      "[30,    20] loss: 1.588\n",
      "[31,    10] loss: 1.596\n",
      "[31,    20] loss: 1.587\n",
      "[32,    10] loss: 1.596\n",
      "[32,    20] loss: 1.586\n",
      "[33,    10] loss: 1.596\n",
      "[33,    20] loss: 1.586\n",
      "[34,    10] loss: 1.596\n",
      "[34,    20] loss: 1.585\n",
      "[35,    10] loss: 1.596\n",
      "[35,    20] loss: 1.585\n",
      "[36,    10] loss: 1.596\n",
      "[36,    20] loss: 1.584\n",
      "[37,    10] loss: 1.596\n",
      "[37,    20] loss: 1.584\n",
      "[38,    10] loss: 1.596\n",
      "[38,    20] loss: 1.583\n",
      "[39,    10] loss: 1.595\n",
      "[39,    20] loss: 1.583\n",
      "[40,    10] loss: 1.595\n",
      "[40,    20] loss: 1.582\n",
      "[41,    10] loss: 1.595\n",
      "[41,    20] loss: 1.582\n",
      "[42,    10] loss: 1.595\n",
      "[42,    20] loss: 1.581\n",
      "[43,    10] loss: 1.595\n",
      "[43,    20] loss: 1.581\n",
      "[44,    10] loss: 1.595\n",
      "[44,    20] loss: 1.580\n",
      "[45,    10] loss: 1.595\n",
      "[45,    20] loss: 1.580\n",
      "[46,    10] loss: 1.595\n",
      "[46,    20] loss: 1.579\n",
      "[47,    10] loss: 1.595\n",
      "[47,    20] loss: 1.579\n",
      "[48,    10] loss: 1.595\n",
      "[48,    20] loss: 1.578\n",
      "[49,    10] loss: 1.595\n",
      "[49,    20] loss: 1.578\n",
      "[50,    10] loss: 1.595\n",
      "[50,    20] loss: 1.578\n",
      "[51,    10] loss: 1.595\n",
      "[51,    20] loss: 1.577\n",
      "[52,    10] loss: 1.595\n",
      "[52,    20] loss: 1.577\n",
      "[53,    10] loss: 1.594\n",
      "[53,    20] loss: 1.576\n",
      "[54,    10] loss: 1.594\n",
      "[54,    20] loss: 1.576\n",
      "[55,    10] loss: 1.594\n",
      "[55,    20] loss: 1.576\n",
      "[56,    10] loss: 1.594\n",
      "[56,    20] loss: 1.575\n",
      "[57,    10] loss: 1.594\n",
      "[57,    20] loss: 1.575\n",
      "[58,    10] loss: 1.594\n",
      "[58,    20] loss: 1.574\n",
      "[59,    10] loss: 1.594\n",
      "[59,    20] loss: 1.574\n",
      "[60,    10] loss: 1.594\n",
      "[60,    20] loss: 1.574\n",
      "[61,    10] loss: 1.594\n",
      "[61,    20] loss: 1.573\n",
      "[62,    10] loss: 1.594\n",
      "[62,    20] loss: 1.573\n",
      "[63,    10] loss: 1.594\n",
      "[63,    20] loss: 1.573\n",
      "[64,    10] loss: 1.594\n",
      "[64,    20] loss: 1.572\n",
      "[65,    10] loss: 1.594\n",
      "[65,    20] loss: 1.572\n",
      "[66,    10] loss: 1.594\n",
      "[66,    20] loss: 1.572\n",
      "[67,    10] loss: 1.594\n",
      "[67,    20] loss: 1.571\n",
      "[68,    10] loss: 1.594\n",
      "[68,    20] loss: 1.571\n",
      "[69,    10] loss: 1.594\n",
      "[69,    20] loss: 1.571\n",
      "[70,    10] loss: 1.594\n",
      "[70,    20] loss: 1.570\n",
      "[71,    10] loss: 1.594\n",
      "[71,    20] loss: 1.570\n",
      "[72,    10] loss: 1.594\n",
      "[72,    20] loss: 1.570\n",
      "[73,    10] loss: 1.594\n",
      "[73,    20] loss: 1.569\n",
      "[74,    10] loss: 1.594\n",
      "[74,    20] loss: 1.569\n",
      "[75,    10] loss: 1.594\n",
      "[75,    20] loss: 1.569\n",
      "[76,    10] loss: 1.593\n",
      "[76,    20] loss: 1.569\n",
      "[77,    10] loss: 1.593\n",
      "[77,    20] loss: 1.568\n",
      "[78,    10] loss: 1.593\n",
      "[78,    20] loss: 1.568\n",
      "[79,    10] loss: 1.593\n",
      "[79,    20] loss: 1.568\n",
      "[80,    10] loss: 1.593\n",
      "[80,    20] loss: 1.567\n",
      "[81,    10] loss: 1.593\n",
      "[81,    20] loss: 1.567\n",
      "[82,    10] loss: 1.593\n",
      "[82,    20] loss: 1.567\n",
      "[83,    10] loss: 1.593\n",
      "[83,    20] loss: 1.567\n",
      "[84,    10] loss: 1.593\n",
      "[84,    20] loss: 1.566\n",
      "[85,    10] loss: 1.593\n",
      "[85,    20] loss: 1.566\n",
      "[86,    10] loss: 1.593\n",
      "[86,    20] loss: 1.566\n",
      "[87,    10] loss: 1.593\n",
      "[87,    20] loss: 1.566\n",
      "[88,    10] loss: 1.593\n",
      "[88,    20] loss: 1.565\n",
      "[89,    10] loss: 1.593\n",
      "[89,    20] loss: 1.565\n",
      "[90,    10] loss: 1.593\n",
      "[90,    20] loss: 1.565\n",
      "[91,    10] loss: 1.593\n",
      "[91,    20] loss: 1.565\n",
      "[92,    10] loss: 1.593\n",
      "[92,    20] loss: 1.564\n",
      "[93,    10] loss: 1.593\n",
      "[93,    20] loss: 1.564\n",
      "[94,    10] loss: 1.593\n",
      "[94,    20] loss: 1.564\n",
      "[95,    10] loss: 1.593\n",
      "[95,    20] loss: 1.564\n",
      "[96,    10] loss: 1.593\n",
      "[96,    20] loss: 1.564\n",
      "[97,    10] loss: 1.592\n",
      "[97,    20] loss: 1.563\n",
      "[98,    10] loss: 1.592\n",
      "[98,    20] loss: 1.563\n",
      "[99,    10] loss: 1.592\n",
      "[99,    20] loss: 1.563\n",
      "[100,    10] loss: 1.592\n",
      "[100,    20] loss: 1.563\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = torch.tensor([X_train[i]], dtype=torch.float32)\n",
    "  \n",
    "        labels = torch.tensor([y_train[i]], dtype=torch.long)\n",
    "   \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.825679063796997\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_test)):\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    inputs = torch.tensor([X_test[i]], dtype=torch.float32)\n",
    "    labels = torch.tensor([y_test[i]], dtype=torch.long)\n",
    "    outputs = model2(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_loss += loss.item()\n",
    "\n",
    "print(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2905, -0.0675, -0.2575, -0.0648,  0.3592],\n",
       "         [-0.2923, -0.0241, -0.2300, -0.0353,  0.3714],\n",
       "         [-0.2806, -0.0065, -0.2332, -0.0280,  0.3773],\n",
       "         [-0.2910, -0.0391, -0.2541, -0.0433,  0.3636],\n",
       "         [-0.3002, -0.0519, -0.2407, -0.0439,  0.3654],\n",
       "         [-0.3257, -0.0832, -0.2585, -0.0571,  0.3607]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import aoc scikit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#predict\n",
    "y_pred = model2(torch.tensor([X_test], dtype=torch.float32))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(y_pred, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4., 1., 3., 4., 2.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, torch.argmax(y_pred, dim=2)[0].detach().numpy())\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
